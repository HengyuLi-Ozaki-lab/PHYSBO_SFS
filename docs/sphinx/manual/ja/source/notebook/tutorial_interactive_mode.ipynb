{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# インタラクティブに実行する\n",
    "\n",
    "以下の流れで、PHYSBO をインタラクティブに実行することができます。\n",
    "\n",
    "1. PHYSBO から次に実行するパラメータを得ます。\n",
    "2. PHYSBO の外部で評価値を得ます。\n",
    "3. 評価値をPHYSBOに登録します。\n",
    "\n",
    "例えば、以下の様な場合に適しています。\n",
    "\n",
    "- 人手による実験を行い、その評価値をPHYSBOに与えたい。\n",
    "- simulator の実行を別プロセスで行うなど、柔軟に実行制御を行いたい。\n",
    "\n",
    "## 探索候補データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import physbo\n",
    "\n",
    "import os\n",
    "import urllib2\n",
    "import ssl\n",
    "import numpy as np\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def download():\n",
    "    if not os.path.exists('data/s5-210.csv'):\n",
    "\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "            \n",
    "        print('Downloading...')\n",
    "        response = urllib2.urlopen(\"http://www.tsudalab.org/files/s5-210.csv\")\n",
    "        with open('data/s5-210.csv', 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "        response.close()\n",
    "        print('Done')\n",
    "        \n",
    "def load_data():\n",
    "    download()\n",
    "    A =  np.asarray(np.loadtxt('data/s5-210.csv',skiprows=1, usecols=(3,4,5,6), delimiter=',') )\n",
    "    X = A[:,0:3]\n",
    "    t  = -A[:,3]\n",
    "    return X, t\n",
    "\n",
    "X, t = load_data()\n",
    "X = physbo.misc.centering(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulator の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simulator:\n",
    "    def __init__( self ):\n",
    "        _, self.t = load_data()\n",
    "    \n",
    "    def __call__( self, action ):\n",
    "        return self.t[action]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy のセット \n",
    "policy = physbo.search.discrete.policy(test_X=X)\n",
    "\n",
    "# シード値のセット \n",
    "policy.set_seed( 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各探索ステップでは以下の処理を行っています。\n",
    "\n",
    "1. `max_num_probes=1, simulator=None` として random_search または bayes_search を実行して actions を得る。\n",
    "2. `t  = simulator(actions)` により評価値(の array) を得る。\n",
    "3. `policy.write(actions, t)`により action に対する評価値を登録する。\n",
    "4. `physbo.search.utility.show_search_results` により履歴を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "simulator = simulator()\n",
    "\n",
    "''' 1st step (random sampling) '''\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t  = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "physbo.search.utility.show_search_results(policy.history, 10)\n",
    "\n",
    "''' 2nd step (random sampling) '''\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "physbo.search.utility.show_search_results(policy.history, 10)\n",
    "\n",
    "''' 3rd step (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)  \n",
    "policy.write(actions, t) \n",
    "physbo.search.utility.show_search_results(policy.history, 10) \n",
    "\n",
    "''' 4-th step (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 50)\n",
    "t = simulator(actions) \n",
    "policy.write(actions, t)\n",
    "physbo.search.utility.show_search_results(policy.history, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中断と再開\n",
    "\n",
    "以下の predictor, training, history を外部ファイルに保存することで、最適化プロセスを中断し、途中から再開することができます。\n",
    "\n",
    "- predictor: 目的関数の予測モデル\n",
    "- training: predictor の学習に用いるデータ (`physbo.variable` オブジェクト）\n",
    "- history: 最適化実行の履歴 (`physbo.search.discrete.results.history` オブジェクト)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('predictor.dump', 'wb') as f:\n",
    "    pickle.dump(policy.predictor, f)\n",
    "policy.training.save('training.npz')\n",
    "policy.history.save('history.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -27.81016746312926\n",
      "50 -th epoch marginal likelihood -38.515180658606\n",
      "100 -th epoch marginal likelihood -44.38603995143297\n",
      "150 -th epoch marginal likelihood -47.687639627010014\n",
      "200 -th epoch marginal likelihood -49.63382459992471\n",
      "250 -th epoch marginal likelihood -50.830087948769304\n",
      "300 -th epoch marginal likelihood -51.59732628884465\n",
      "350 -th epoch marginal likelihood -52.11396264674491\n",
      "400 -th epoch marginal likelihood -52.48246995632367\n",
      "450 -th epoch marginal likelihood -52.76279457032902\n",
      "500 -th epoch marginal likelihood -52.990202959467595\n",
      "Done\n",
      "\n",
      "0005-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-0.959371 (action = 6568)\n",
      "f(x)=-0.990530 (action = 5365)\n",
      "f(x)=-0.996815 (action = 8990)\n",
      "f(x)=-1.118381 (action = 2987)\n",
      "f(x)=-1.009032 (action = 1643)\n",
      "f(x)=-1.019266 (action = 11951)\n",
      "f(x)=-1.033086 (action = 8473)\n",
      "f(x)=-1.056302 (action = 11470)\n",
      "f(x)=-0.990425 (action = 333)\n",
      "f(x)=-1.124811 (action = 15021)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0 -th epoch marginal likelihood -10.605104685648527\n",
      "50 -th epoch marginal likelihood -32.397438459895184\n",
      "100 -th epoch marginal likelihood -45.3712800209272\n",
      "150 -th epoch marginal likelihood -53.19991464647401\n",
      "200 -th epoch marginal likelihood -58.099967852367534\n",
      "250 -th epoch marginal likelihood -61.26712642997859\n",
      "300 -th epoch marginal likelihood -63.3731356870413\n",
      "350 -th epoch marginal likelihood -64.81121730168385\n",
      "400 -th epoch marginal likelihood -65.81992198626841\n",
      "450 -th epoch marginal likelihood -66.54832259792526\n",
      "500 -th epoch marginal likelihood -67.09178759546563\n",
      "Done\n",
      "\n",
      "0006-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-0.970388 (action = 6789)\n",
      "f(x)=-1.003224 (action = 3057)\n",
      "f(x)=-0.975826 (action = 6196)\n",
      "f(x)=-1.022587 (action = 6758)\n",
      "f(x)=-1.137064 (action = 3432)\n",
      "f(x)=-1.150921 (action = 8)\n",
      "f(x)=-2.497328 (action = 17945)\n",
      "f(x)=-2.497145 (action = 17981)\n",
      "f(x)=-0.983122 (action = 6695)\n",
      "f(x)=-1.189734 (action = 6011)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# policy を削除\n",
    "del policy\n",
    "\n",
    "# 保存した policy をロード \n",
    "policy = physbo.search.discrete.policy(test_X=X)\n",
    "policy.load('history.npz', 'training.npz', 'predictor.dump')\n",
    "\n",
    "''' 5-th probe (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions) \n",
    "policy.write(actions, t) \n",
    "physbo.search.utility.show_search_results(policy.history, 10) \n",
    "\n",
    "# predictor と training を個別に指定することも可\n",
    "''' 6-th probe (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                            predictor=policy.predictor, training=policy.training,\n",
    "                                            simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions) \n",
    "policy.write(actions, t) \n",
    "physbo.search.utility.show_search_results(policy.history, 10) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
