{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# インタラクティブに実行する\n",
    "\n",
    "以下の流れで、COMBO をインタラクティブに実行することができます。\n",
    "\n",
    "1. COMBO から次に実行するパラメータを得る\n",
    "2. COMBO の外部で評価値を得る\n",
    "3. 評価値をCOMBOに登録する\n",
    "\n",
    "例えば、以下の様な場合に適しています。\n",
    "\n",
    "- 人手による実験を行い、その評価値をCOMBOに与えたい\n",
    "- simulator の実行を別プロセスで行うなど、柔軟に実行制御を行いたい\n",
    "\n",
    "## 探索候補データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import combo\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def download():\n",
    "    if not os.path.exists('data/s5-210.csv'):\n",
    "\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "            \n",
    "        print('Downloading...')\n",
    "        with urllib.request.urlopen(\"http://www.tsudalab.org/files/s5-210.csv\") as response, open('data/s5-210.csv', 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "        print('Done')\n",
    "        \n",
    "def load_data():\n",
    "    download()\n",
    "    A =  np.asarray(np.loadtxt('data/s5-210.csv',skiprows=1,delimiter=',') )\n",
    "    X = A[:,0:3]\n",
    "    t  = -A[:,3]\n",
    "    return X, t\n",
    "\n",
    "X, t = load_data()\n",
    "X = combo.misc.centering( X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulator の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simulator:\n",
    "    def __init__( self ):\n",
    "        _, self.t = load_data()\n",
    "    \n",
    "    def __call__( self, action ):\n",
    "        return self.t[action]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# policy のセット \n",
    "policy = combo.search.discrete.policy(test_X=X)\n",
    "\n",
    "# シード値のセット \n",
    "policy.set_seed( 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各探索ステップでは以下の処理を行っています。\n",
    "\n",
    "1. `max_num_probes=1, simulator=None` として random_search または bayes_search を実行して actions を得る\n",
    "2. `t  = simulator(actions)` により評価値(の array) を得る\n",
    "3. `policy.write(actions, t)`により action に対する評価値を登録する\n",
    "4. `combo.search.utility.show_search_results` により履歴を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interactive mode stars ... \n",
      " \n",
      "0001-th multiple probe search (random) \n",
      "\n",
      "current best f(x) = -0.980054 (best action = 4547) \n",
      "list of simulation results\n",
      "f(x)=-1.070602 (action = 15673)\n",
      "f(x)=-1.009056 (action = 9559)\n",
      "f(x)=-1.195844 (action = 16927)\n",
      "f(x)=-0.980054 (action = 4547)\n",
      "f(x)=-0.992820 (action = 2553)\n",
      "f(x)=-1.146676 (action = 13144)\n",
      "f(x)=-1.006255 (action = 10827)\n",
      "f(x)=-0.999862 (action = 1995)\n",
      "f(x)=-1.055445 (action = 10763)\n",
      "f(x)=-1.100970 (action = 16450)\n",
      "\n",
      "\n",
      "0002-th multiple probe search (random) \n",
      "\n",
      "current best f(x) = -0.980054 (best action = 4547) \n",
      "list of simulation results\n",
      "f(x)=-1.208666 (action = 13085)\n",
      "f(x)=-1.069404 (action = 15133)\n",
      "f(x)=-1.031642 (action = 1706)\n",
      "f(x)=-1.016702 (action = 2464)\n",
      "f(x)=-1.172569 (action = 17812)\n",
      "f(x)=-1.082219 (action = 16533)\n",
      "f(x)=-1.025272 (action = 1336)\n",
      "f(x)=-1.031761 (action = 10076)\n",
      "f(x)=-0.984972 (action = 8876)\n",
      "f(x)=-1.107730 (action = 15577)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epoch, marginal likelihood -22.8397384798\n",
      "50-th epoch, marginal likelihood -24.1776171399\n",
      "100-th epoch, marginal likelihood -24.8310182858\n",
      "150-th epoch, marginal likelihood -25.1541614865\n",
      "200-th epoch, marginal likelihood -25.334465628\n",
      "250-th epoch, marginal likelihood -25.4551550106\n",
      "300-th epoch, marginal likelihood -25.5500914536\n",
      "350-th epoch, marginal likelihood -25.6313012793\n",
      "400-th epoch, marginal likelihood -25.7023874574\n",
      "450-th epoch, marginal likelihood -25.7643476773\n",
      "500-th epoch, marginal likelihood -25.8176978448\n",
      "Done\n",
      "\n",
      " Parameters of Gaussian kernel \n",
      " \n",
      " width  =  [ 3.]\n",
      " scale  =  1.0\n",
      " scale2 =  1.0\n",
      " \n",
      "\n",
      "0003-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.965358 (best action = 7677) \n",
      "list of simulation results\n",
      "f(x)=-1.080313 (action = 8128)\n",
      "f(x)=-0.965358 (action = 7677)\n",
      "f(x)=-1.069888 (action = 6744)\n",
      "f(x)=-1.000745 (action = 5438)\n",
      "f(x)=-0.991714 (action = 5993)\n",
      "f(x)=-1.089947 (action = 11497)\n",
      "f(x)=-1.054229 (action = 1253)\n",
      "f(x)=-1.044660 (action = 4687)\n",
      "f(x)=-1.054012 (action = 5246)\n",
      "f(x)=-0.965678 (action = 5031)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epoch, marginal likelihood -30.6042738797\n",
      "50-th epoch, marginal likelihood -35.8323970997\n",
      "100-th epoch, marginal likelihood -38.5632285433\n",
      "150-th epoch, marginal likelihood -40.0195014495\n",
      "200-th epoch, marginal likelihood -40.8402155845\n",
      "250-th epoch, marginal likelihood -41.3330181381\n",
      "300-th epoch, marginal likelihood -41.6536564484\n",
      "350-th epoch, marginal likelihood -41.883012718\n",
      "400-th epoch, marginal likelihood -42.0631217907\n",
      "450-th epoch, marginal likelihood -42.2153702356\n",
      "500-th epoch, marginal likelihood -42.3501791876\n",
      "Done\n",
      "\n",
      " Parameters of Gaussian kernel \n",
      " \n",
      " width  =  [ 0.66107133]\n",
      " scale  =  0.0763818155444\n",
      " scale2 =  0.00583418174586\n",
      " \n",
      "\n",
      "0004-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.963138 (best action = 7308) \n",
      "list of simulation results\n",
      "f(x)=-0.980979 (action = 4735)\n",
      "f(x)=-0.999359 (action = 7857)\n",
      "f(x)=-0.963138 (action = 7308)\n",
      "f(x)=-1.120441 (action = 2785)\n",
      "f(x)=-1.060749 (action = 5669)\n",
      "f(x)=-0.977188 (action = 10857)\n",
      "f(x)=-1.019301 (action = 11987)\n",
      "f(x)=-1.283628 (action = 12002)\n",
      "f(x)=-0.991675 (action = 5957)\n",
      "f(x)=-1.027484 (action = 5303)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulator = simulator()\n",
    "\n",
    "''' 1st step (random sampling) '''\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t  = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "combo.search.utility.show_search_results(policy.history, 10)\n",
    "\n",
    "''' 2nd step (random sampling) '''\n",
    "actions = policy.random_search(max_num_probes=1, num_search_each_probe=10, simulator=None)\n",
    "t = simulator(actions)\n",
    "policy.write(actions, t)\n",
    "combo.search.utility.show_search_results(policy.history, 10)\n",
    "\n",
    "''' 3rd step (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions)  \n",
    "policy.write(actions, t) \n",
    "combo.search.utility.show_search_results(policy.history, 10) \n",
    "\n",
    "''' 4-th step (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 50)\n",
    "t = simulator(actions) \n",
    "policy.write(actions, t)\n",
    "combo.search.utility.show_search_results(policy.history, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中断と再開\n",
    "\n",
    "以下の predictor, training, history を外部ファイルに保存することで、最適化プロセスを中断し、途中から再開することができます。\n",
    "\n",
    "- predictor: 目的関数の予測モデル\n",
    "- training: predictor の学習に用いるデータ (`combo.variable` オブジェクト）\n",
    "- history: 最適化実行の履歴 (`combo.search.discrete.results.history` オブジェクト)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('predictor.dump', 'wb') as f:\n",
    "    pickle.dump(policy.predictor, f)\n",
    "policy.training.save('training.npz')\n",
    "policy.history.save('history.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epoch, marginal likelihood -27.8101674631\n",
      "50-th epoch, marginal likelihood -38.5151806586\n",
      "100-th epoch, marginal likelihood -44.3860399514\n",
      "150-th epoch, marginal likelihood -47.687639627\n",
      "200-th epoch, marginal likelihood -49.6338245999\n",
      "250-th epoch, marginal likelihood -50.8300879488\n",
      "300-th epoch, marginal likelihood -51.5973262888\n",
      "350-th epoch, marginal likelihood -52.1139626467\n",
      "400-th epoch, marginal likelihood -52.4824699563\n",
      "450-th epoch, marginal likelihood -52.7627945703\n",
      "500-th epoch, marginal likelihood -52.9902029595\n",
      "Done\n",
      "\n",
      " Parameters of Gaussian kernel \n",
      " \n",
      " width  =  [ 0.65397154]\n",
      " scale  =  0.0755729095878\n",
      " scale2 =  0.00571126466357\n",
      " \n",
      "\n",
      "0005-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-0.959371 (action = 6568)\n",
      "f(x)=-0.990530 (action = 5365)\n",
      "f(x)=-0.996815 (action = 8990)\n",
      "f(x)=-1.118381 (action = 2987)\n",
      "f(x)=-1.009032 (action = 1643)\n",
      "f(x)=-1.019266 (action = 11951)\n",
      "f(x)=-1.033086 (action = 8473)\n",
      "f(x)=-1.056302 (action = 11470)\n",
      "f(x)=-0.990425 (action = 333)\n",
      "f(x)=-1.124811 (action = 15021)\n",
      "\n",
      "\n",
      "Start the initial hyper parameter searching ...\n",
      "Done\n",
      "\n",
      "Start the hyper parameter learning ...\n",
      "0-th epoch, marginal likelihood -10.6051046856\n",
      "50-th epoch, marginal likelihood -32.3974384599\n",
      "100-th epoch, marginal likelihood -45.3712800209\n",
      "150-th epoch, marginal likelihood -53.1999146465\n",
      "200-th epoch, marginal likelihood -58.0999678524\n",
      "250-th epoch, marginal likelihood -61.26712643\n",
      "300-th epoch, marginal likelihood -63.373135687\n",
      "350-th epoch, marginal likelihood -64.8112173017\n",
      "400-th epoch, marginal likelihood -65.8199219863\n",
      "450-th epoch, marginal likelihood -66.5483225979\n",
      "500-th epoch, marginal likelihood -67.0917875955\n",
      "Done\n",
      "\n",
      " Parameters of Gaussian kernel \n",
      " \n",
      " width  =  [ 0.6816218]\n",
      " scale  =  0.0894674917193\n",
      " scale2 =  0.00800443207453\n",
      " \n",
      "\n",
      "0006-th multiple probe search (EI) \n",
      "\n",
      "current best f(x) = -0.959371 (best action = 6568) \n",
      "list of simulation results\n",
      "f(x)=-0.970388 (action = 6789)\n",
      "f(x)=-1.003224 (action = 3057)\n",
      "f(x)=-0.975826 (action = 6196)\n",
      "f(x)=-1.022587 (action = 6758)\n",
      "f(x)=-1.137064 (action = 3432)\n",
      "f(x)=-1.150921 (action = 8)\n",
      "f(x)=-2.497328 (action = 17945)\n",
      "f(x)=-2.497145 (action = 17981)\n",
      "f(x)=-0.983122 (action = 6695)\n",
      "f(x)=-1.189734 (action = 6011)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# policy を削除\n",
    "del policy\n",
    "\n",
    "# 保存した policy をロード \n",
    "policy = combo.search.discrete.policy(test_X=X)\n",
    "policy.load('history.npz', 'training.npz', 'predictor.dump')\n",
    "\n",
    "''' 5-th probe (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                                      simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions) \n",
    "policy.write(actions, t) \n",
    "combo.search.utility.show_search_results(policy.history, 10) \n",
    "\n",
    "# predictor と training を個別に指定することも可\n",
    "''' 6-th probe (bayesian optimization) '''\n",
    "actions = policy.bayes_search(max_num_probes=1, num_search_each_probe=10, \n",
    "                                            predictor=policy.predictor, training=policy.training,\n",
    "                                            simulator=None, score='EI', interval=0,  num_rand_basis = 0)\n",
    "t = simulator(actions) \n",
    "policy.write(actions, t) \n",
    "combo.search.utility.show_search_results(policy.history, 10) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
